# -*- coding: utf-8 -*-
"""FinalGradientDescent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OzAkR6PL6Bj5CIbe1ipRXQopu2y0Maq_
"""

# Imports
import numpy as np # Used to make calculations easier
import pandas as pd # Used to read our input data in csv format
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import SGDRegressor
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.preprocessing import StandardScaler

# Raw URL of the dataset
url = 'https://raw.githubusercontent.com/sanspandey45/Car-Prediction-Model/main/CarData.csv'

# Load dataset into a DataFrame
df = pd.read_csv(url)

# Display the first few rows of DataFrame
df.head()

# Plotting various features vs. Price
from matplotlib import pyplot as plt
df.plot(kind='scatter', x='Length', y='Price', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(True)

df.plot(kind='scatter', x='Width', y='Price', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(True)

df.plot(kind='scatter', x='CurbWeight', y='Price', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(True)

df.plot(kind='scatter', x='NumOfCylinders', y='Price', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(True)

df.plot(kind='scatter', x='Horsepower', y='Price', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(True)

df.plot(kind='scatter', x='CityMpg', y='Price', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(True)



# Correlation Matrix
plt.figure(figsize=(8, 6))  # Adjust figure size if needed
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

# As WheelBase is not as strongly correlated nor much of a concern to most people, it will be disregarded from the dataset.

# Now have 8 features involved.
features_of_interest = ["Length", "Width", "CurbWeight", "NumOfCylinders", "EngineSize", "Horsepower", "CityMpg", "HighwayMpg"]
df[features_of_interest].describe()

# Setting X to independent variables and y to dependent variable
X = df[features_of_interest]
y = df['Price']

s = StandardScaler()
X = pd.DataFrame(s.fit(X).fit_transform(X))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=3)
print(X_train.shape) # Prints: (num of instances in training set, num of features)
print(X_test.shape) # Prints: (num of instances in testing set, num of features)
print(y_train.shape) # Prints: (num of instances in training set,)
print(y_test.shape) # Prints: (num of instances in testing set,)

# So that we can alter learning rate
model = SGDRegressor(
    eta0=0.001,                # Initial learning rate
    learning_rate='constant', # Learning rate schedule
    max_iter=1000,            # Maximum number of iterations
)

model.fit(X_train, y_train)

# Training Data
y_train_predict = model.predict(X_train)
rmse = (np.sqrt(mean_squared_error(y_train, y_train_predict)))
r2 = model.score(X_train, y_train)

print('Training RMSE: {}'.format(rmse))
print('Training R2: {}'.format(r2))
print("")

# Testing Data
y_test_predict = model.predict(X_test)
rmse = (np.sqrt(mean_squared_error(y_test, y_test_predict)))
r2 = model.score(X_test, y_test)

print('Testing RMSE: {}'.format(rmse))
print('Testing R2: {}'.format(r2))
print("")

# Print Mean Average Percent Error (accuracy on test data)
mape = mean_absolute_percentage_error(y_test, y_test_predict) * 100
print(f"MAPE: {mape}%")

# Plot MSE vs Number of Iterations

# Range of iterations to test
iterations = range(100, 1001, 50)

mse_train = []
mse_test = []

# Loop through different iterations
for iter in iterations:
    # Train the model with current iteration
    model = SGDRegressor(
        eta0=0.001,
        learning_rate='constant',
        max_iter=iter
    )
    model.fit(X_train, y_train)

    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    mse_train.append(mean_squared_error(y_train, y_train_pred))
    mse_test.append(mean_squared_error(y_test, y_test_pred))

# Plot MSE values
plt.plot(iterations, mse_train, label='Training MSE')
plt.plot(iterations, mse_test, label='Testing MSE')
plt.xlabel('Number of Iterations')
plt.ylabel('Mean Squared Error (MSE)')
plt.title('MSE vs Number of Iterations')
plt.legend()
plt.show()

# Plot Weight/Parameters vs Number of Iterations

# Get weights (coefficients) at each iteration
weights = []
for iter in range(100, 1001, 50):
    model = SGDRegressor(
        eta0=0.001,
        learning_rate='constant',
        max_iter=iter
    )
    model.fit(X_train, y_train)
    weights.append(model.coef_)

# Convert weights to a DataFrame for easier plotting
weights_df = pd.DataFrame(weights, columns=features_of_interest)

# Plot the weights vs iterations
plt.figure(figsize=(10, 6))
for feature in features_of_interest:
    plt.plot(range(100, 1001, 50), weights_df[feature], label=feature)

plt.xlabel('Number of Iterations')
plt.ylabel('Weights (Coefficients)')
plt.title('Weights vs Number of Iterations')
plt.legend()
plt.show()

# Plot Model Predictions vs Actual Data for test data

import matplotlib.pyplot as plt
plt.scatter(y_test, y_test_predict)
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual vs Predicted Prices on Test Data')
plt.show()

# Same thing for training data
import matplotlib.pyplot as plt
plt.scatter(y_train, y_train_predict)
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Actual vs Predicted Prices on Training Data')
plt.show()

